# AI Learning Notes (Embeddings, LLMs, RAG)

## âœ… 1. Embeddings + Similarity

- Text embeddings convert sentences into high-dimensional vectors.
- Cosine similarity can measure semantic similarity between two text inputs.

Example:
```text
â€œHow are you?â€ vs â€œWhatâ€™s up?â€ â†’ high similarity
â€œHow are you?â€ vs â€œBananaâ€     â†’ low similarity
```

## âœ… 2. Retrieval-Augmented Generation (RAG)

**RAG** is a design pattern that enhances LLM responses using relevant context from a knowledge base or dataset.  
Instead of relying only on the model's training, it retrieves relevant information and injects it into the prompt dynamically.

---

### ğŸ”„ RAG Workflow

```text
User Query
   â†“
Embed the Query (OpenAI / HuggingFace model)
   â†“
Compare with Vector Store (cosine similarity)
   â†“
Retrieve Top-K Relevant Chunks
   â†“
Construct Prompt:
  - Inject Retrieved Context
  - Append User Question
   â†“
Send to LLM (e.g., GPT-3.5 / 4)
   â†“
LLM Generates Answer Using Both
